{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses on the learning ability of the different architectures\n",
    "\n",
    "We will analyse the learning ability of the different architectures according to their size (number of learnable parameters).\n",
    "In these experiences, matrices have dimension of $10 \\times 10$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralNetwork import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# Choose te best device according to the host machine\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loads datasets\n",
    "training_set = cuboidDataset(\"en-fr.matrices.train.npz\", device=device)\n",
    "validation_set = cuboidDataset(\"en-fr.matrices.validation.npz\", device=device)\n",
    "#test_set = cuboidDataset(\"en-fr.matrices.test.npz\", device=device)\n",
    "\n",
    "matrix_length = training_set.getmatrixlength()\n",
    "sizes_to_try = list(range(100000, 1000000, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model:\n",
    "There is no parameters that changes the number of learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleLinear(matrix_length)\n",
    "net_size = numberofparameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "\n",
    "plt.plot([net_size], [converged_loss], label='SimpleLinear')\n",
    "print(\"Linear model: Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected model:\n",
    "\n",
    "This model give good results when it used with two or three hidden layers.\n",
    "We will try these two modes, each hidden layers will have the same number of neurons since\n",
    "we don't have any rule for that.\n",
    "\n",
    "We will call $n$ the number of neurons on each layers and $S$ the number of learnable parameters.\n",
    "\n",
    "### With two hidden layers:\n",
    "\n",
    "We have:\n",
    "$S = n^2 + 902n + 300$\n",
    "\n",
    "So:\n",
    "$n = -\\frac{902}{2} + \\sqrt{S + (\\frac{902}{2})^2 - 300}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_from_n(n):\n",
    "    return n*(n + 902) + 300\n",
    "\n",
    "def n_from_S(S):\n",
    "    return sqrt(S + 451**2 - 300) - 451\n",
    "\n",
    "loss_list = list()\n",
    "size_list = list()\n",
    "for S in sizes_to_try:\n",
    "    n = round(n_from_S(S))\n",
    "    size_list.append(n)\n",
    "    net = FullyConnectedNetwork(matrix_length, layers_size=[n, n])\n",
    "    net_size = numberofparameters(net)\n",
    "    \n",
    "    converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "    loss_list.append(converged_loss)\n",
    "\n",
    "plt.plot(size_list, loss_list, label='FullyConnected (2hl)')\n",
    "print(\"Fully Connected model (2hl): Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With three hidden layers:\n",
    "\n",
    "We have:\n",
    "$S = 2n^2 + 903n + 300$\n",
    "\n",
    "So:\n",
    "$n = \\frac{-903 + \\sqrt{8S + 903^2 - 8\\times300}}{4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_from_n(n):\n",
    "    return n*(2*n + 903) + 300\n",
    "\n",
    "def n_from_S(S):\n",
    "    return (sqrt((8*S) + (903**2) - (8*300))-903)/4\n",
    "\n",
    "loss_list = list()\n",
    "size_list = list()\n",
    "for S in sizes_to_try):\n",
    "    n = round(n_from_S(S))\n",
    "    size_list.append(n)\n",
    "    net = FullyConnectedNetwork(matrix_length, layers_size=[n, n, n])\n",
    "    net_size = numberofparameters(net)\n",
    "    \n",
    "    converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "    loss_list.append(converged_loss)\n",
    "\n",
    "plt.plot(size_list, loss_list, label='FullyConnected (3hl)')\n",
    "print(\"Fully Connected model (3hl): Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Channeled model:\n",
    "\n",
    "\n",
    "### With two hidden layers:\n",
    "\n",
    "We have:\n",
    "$S = 3n^2 + 1506n + 300$\n",
    "\n",
    "So:\n",
    "$n = \\frac{-1506 + \\sqrt{12S + 2264436}}{6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_from_n(n):\n",
    "    return n*(3*n + 1506) + 300\n",
    "\n",
    "def n_from_S(S):\n",
    "    return (sqrt(12*S + 2264436)-1506)/6\n",
    "\n",
    "size_list = list()\n",
    "for S in sizes_to_try:\n",
    "    n = round(n_from_S(S))\n",
    "    size_list.append(n)\n",
    "    net = FullyConnectedNetwork(matrix_length, layers_size=[n, n])\n",
    "    net_size = numberofparameters(net)\n",
    "    converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "    loss_list.append(converged_loss)\n",
    "\n",
    "plt.plot(size_list, loss_list, label='Matrix_channeled (2hl)')\n",
    "print(\"Matrix channeled model (2hl): Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With three hidden layers:\n",
    "\n",
    "We have:\n",
    "$S = 6n^2 + 1509n + 300$\n",
    "\n",
    "So:\n",
    "$n = \\frac{-1509 + \\sqrt{24S + 2269881}}{12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_from_n(n):\n",
    "    return n*(6*n + 1509) + 300\n",
    "\n",
    "def n_from_S(S):\n",
    "    return (sqrt(34*S + 2269881)-1509)/12\n",
    "\n",
    "size_list = list()\n",
    "for S in sizes_to_try:\n",
    "    n = round(n_from_S(S))\n",
    "    size_list.append(n)\n",
    "    net = FullyConnectedNetwork(matrix_length, layers_size=[n, n, n])\n",
    "    net_size = numberofparameters(net)\n",
    "    converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "    loss_list.append(converged_loss)\n",
    "\n",
    "plt.plot(size_list, loss_list, label='Matrix_channeled (3hl)')\n",
    "print(\"Matrix channeled model (3hl): Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel Channeled model:\n",
    "\n",
    "\n",
    "### With two hidden layers:\n",
    "\n",
    "We have:\n",
    "$S = 300n^2 + 120900n + 300$\n",
    "\n",
    "So:\n",
    "$n = \\frac{-120900 + \\sqrt{1200S + 14616450000}}{600}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_from_n(n):\n",
    "    return n*(300*n + 120900) + 300\n",
    "\n",
    "def n_from_S(S):\n",
    "    return (sqrt(1200*S + 14616450000)-120900)/600\n",
    "\n",
    "size_list = list()\n",
    "for S in sizes_to_try:\n",
    "    n = round(n_from_S(S))\n",
    "    size_list.append(n)\n",
    "    net = FullyConnectedNetwork(matrix_length, layers_size=[n, n])\n",
    "    net_size = numberofparameters(net)\n",
    "    converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "    loss_list.append(converged_loss)\n",
    "\n",
    "plt.plot(size_list, loss_list, label='Pixel_channeled (2hl)')\n",
    "print(\"Pixel channeled model (2hl): Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With three hidden layers:\n",
    "\n",
    "We have:\n",
    "$S = 600n^2 + 121200n + 300$\n",
    "\n",
    "So:\n",
    "$n = \\frac{-121200 + \\sqrt{2400S + 14688720000}}{1200}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_from_n(n):\n",
    "    return n*(600*n + 121200) + 300\n",
    "\n",
    "def n_from_S(S):\n",
    "    return (sqrt(2400*S + 14688720000)-121200)/1200\n",
    "\n",
    "size_list = list()\n",
    "for S in sizes_to_try:\n",
    "    n = round(n_from_S(S))\n",
    "    size_list.append(n)\n",
    "    net = FullyConnectedNetwork(matrix_length, layers_size=[n, n, n])\n",
    "    net_size = numberofparameters(net)\n",
    "    converged_loss = train(net, \n",
    "                       training_set, \n",
    "                       validation_set)\n",
    "    loss_list.append(converged_loss)\n",
    "\n",
    "plt.plot(size_list, loss_list, label='Pixel_channeled (3hl)')\n",
    "print(\"Pixel channeled model (3hl): Number of parameters: \", net_size, \" ; Converged loss: \", converged_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Size of the network (number of learnable parameters).\")\n",
    "plt.ylabel(\"Average loss after convergence.\")\n",
    "plt.savefig(\"Architecture_comparisons.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
